{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save keyword_list & keyword_similarity from w2v tranined data\n",
    "# save similarity data larger than certain threshold (.3)\n",
    "# multiprocessing\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "import gensim\n",
    "import os\n",
    "import csv\n",
    "from multiprocessing import Pool\n",
    "\n",
    "%cd Reddit\n",
    "\n",
    "# hyper parameters of word2vec\n",
    "eb_size = 50\n",
    "w2v_win = 5\n",
    "mincount = 100\n",
    "epoch_size = 10\n",
    "\n",
    "path = \"model_save_{0}_{1}_{2}_{3}_recommend\".format(eb_size,w2v_win,mincount,epoch_size)\n",
    "\n",
    "if os.path.isdir(path + \"/keyword\") == False:\n",
    "    os.mkdir(path + \"/keyword\")\n",
    "\n",
    "def cal_keyword(month_start):\n",
    "    iter = 0\n",
    "    for i in range(2011,2018):\n",
    "        for ii in range(month_start,month_start+1):\n",
    "            for iii in range(1,32):\n",
    "                year = i\n",
    "                month = ii\n",
    "                day_m = iii\n",
    "                if os.path.isfile(path + \"/w2v_trained_reddit_{0}_{1}_{2}_{3}_{4}_{5}_{6}_recommend\".format(year,month,day_m,eb_size,w2v_win,mincount,epoch_size)) == True:\n",
    "                    print(i,ii,iii,iter)\n",
    "                    model = gensim.models.Word2Vec.load(path + \"/w2v_trained_reddit_{0}_{1}_{2}_{3}_{4}_{5}_{6}_recommend\".format(year,month,day_m,eb_size,w2v_win,mincount,epoch_size))\n",
    "\n",
    "                    vocab = list(model.wv.vocab)\n",
    "\n",
    "                    # write keyword\n",
    "                    resultFyle = open(path + \"/keyword/\" + \"keyword_{0}_{1}_{2}\".format(year,month,day_m) + \".csv\",'w')\n",
    "                    wr = csv.writer(resultFyle, dialect='excel')\n",
    "                    for ki,item in enumerate(vocab):\n",
    "                        wr.writerow([ki,item])\n",
    "                    resultFyle.close()\n",
    "\n",
    "                    # write keyword similarity\n",
    "                    resultFyle = open(path + \"/keyword/\" + \"keyword_sim_{0}_{1}_{2}\".format(year,month,day_m) + \".csv\",'w')\n",
    "                    wr = csv.writer(resultFyle, dialect='excel')\n",
    "                    for ki,item_1 in enumerate(vocab):\n",
    "                        for kii,item_2 in enumerate(vocab):\n",
    "\n",
    "                            if model.wv.similarity(item_1, item_2) > .3 and ki < kii:\n",
    "                                wr.writerow([ki, kii, model.wv.similarity(item_1, item_2)])\n",
    "                    resultFyle.close()\n",
    "\n",
    "\n",
    "                    iter = iter + 1\n",
    "                    \n",
    "                    \n",
    "pool = Pool(processes = 12)\n",
    "pool.map(cal_keyword,list(range(1,13)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorf",
   "language": "python",
   "name": "tensorf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
