{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install gensim\n",
    "import sys\n",
    "!{sys.executable} -m pip install gensim --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install xz related to lzma\n",
    "%cd Reddit\n",
    "!curl -L -O http://tukaani.org/xz/xz-5.0.4.tar.gz\n",
    "!tar -zxvf xz-5.0.4.tar.gz\n",
    "%cd xz-5.0.4\n",
    "!./configure --prefix=$HOME\n",
    "!make\n",
    "!make check\n",
    "!make install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install lzma to uncompress xz file\n",
    "import sys\n",
    "!{sys.executable} -m pip install backports.lzma --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word2vec (all score)\n",
    "\n",
    "import json\n",
    "import gensim\n",
    "import multiprocessing\n",
    "import bz2\n",
    "import math\n",
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "import time\n",
    "from backports import lzma\n",
    "\n",
    "%cd Reddit\n",
    "\n",
    "# hyper parameters of word2vec\n",
    "eb_size = 100\n",
    "w2v_win = 5\n",
    "mincount = 100\n",
    "epoch_size = 10\n",
    "\n",
    "path = \"model_save_{0}_{1}_{2}_{3}\".format(eb_size,w2v_win,mincount,epoch_size)\n",
    "\n",
    "# parameters to continue training\n",
    "ini = 1 # 0 if continue to train, 1 if initiate to train\n",
    "#year = 2017\n",
    "#month = 11\n",
    "#day_m = 30\n",
    "#model = gensim.models.Word2Vec.load(path + \"/w2v_trained_reddit_{0}_{1}_{2}_{3}_{4}_{5}_{6}\".format(year,int(month),day_m,eb_size,w2v_win,mincount,epoch_size))\n",
    "\n",
    "if os.path.isdir(path) == False:\n",
    "    os.mkdir(path)\n",
    "     \n",
    "sys.stdout = open(\"model_log_{0}_{1}_{2}_{3}.txt\".format(eb_size,w2v_win,mincount,epoch_size), \"a\")\n",
    "\n",
    "print(\"word2vec training\")\n",
    "print(datetime.datetime.now())\n",
    "print(\"embedding_size: {0}\".format(eb_size))\n",
    "print(\"w2v_window_size: {0}\".format(w2v_win))\n",
    "print(\"w2v_min_count: {0}\".format(mincount))\n",
    "print(\"w2v_epoch_size: {0}\".format(epoch_size))\n",
    "sys.stdout.flush()\n",
    "\n",
    "# there are few lines that are not in json format\n",
    "def is_json(line):\n",
    "    try:\n",
    "        json_object = json.loads(line)\n",
    "    except ValueError:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "for i in range(2011,2018):\n",
    "    for ii in range(1,13):\n",
    "        year = i\n",
    "        if ii<10:\n",
    "            month = \"0{0}\".format(ii)\n",
    "        else:\n",
    "            month = ii\n",
    "            \n",
    "        print(\"start: read file from bz2: {0}_{1}\".format(year,month))\n",
    "        print(datetime.datetime.now())\n",
    "        sys.stdout.flush()\n",
    "        \n",
    "        if os.path.isfile(\"RS_{0}-{1}.bz2\".format(year,month)):\n",
    "                data_file = bz2.BZ2File(\"RS_{0}-{1}.bz2\".format(year,month)).readlines()\n",
    "        elif os.path.isfile(\"RS_{0}-{1}.xz\".format(year,month)):\n",
    "                data_file = lzma.open(\"RS_{0}-{1}.xz\".format(year,month)).readlines()\n",
    "   \n",
    "        data_time = []\n",
    "        data_title = []\n",
    "        data_time_sort = []\n",
    "        data_title_sort = []\n",
    "        for line in data_file:\n",
    "            if is_json(line) is True:\n",
    "                line_load = json.loads(line)\n",
    "                data_time.append(int(line_load[\"created_utc\"]))\n",
    "                data_title.append(gensim.utils.simple_preprocess(line_load[\"title\"]))\n",
    "              \n",
    "        data_time_sort = sorted(data_time)\n",
    "        data_title_sort = [x for _,x in sorted(zip(data_time,data_title))]\n",
    "        \n",
    "        data_file.clear()\n",
    "        data_time.clear()\n",
    "        data_title.clear()\n",
    "        \n",
    "        print(\"end: read file from bz2: {0}_{1}\".format(year,month))\n",
    "        print(datetime.datetime.now())\n",
    "        sys.stdout.flush()\n",
    "        \n",
    "        for ind, ut in enumerate(data_time_sort):\n",
    "            ut_to_time = time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(ut))\n",
    "            day_data = int(ut_to_time[8:10])\n",
    "            if ind == 0:\n",
    "                day_data_temp = day_data\n",
    "                temp = []\n",
    "            \n",
    "            if day_data == day_data_temp: # cumulate data\n",
    "                temp.append(data_title_sort[ind])   \n",
    "            if day_data != day_data_temp or ind == len(data_time_sort) - 1: # update day & traning previous data(temp)\n",
    "                print([year,int(month),day_data_temp,datetime.datetime.now()])\n",
    "                sys.stdout.flush()\n",
    "                # training previous updated data\n",
    "                if ini == 1: # initial word2vec training\n",
    "                    model = gensim.models.Word2Vec(temp, size=eb_size, window=w2v_win, min_count=mincount,workers=2*multiprocessing.cpu_count())\n",
    "                    ini = 0\n",
    "                else: # online word2vec training\n",
    "                    model.build_vocab(temp, update=True)\n",
    "                model.train(temp,total_examples=len(temp),epochs=epoch_size)\n",
    "                model.save(path + \"/w2v_trained_reddit_{0}_{1}_{2}_{3}_{4}_{5}_{6}\".format(year,int(month),day_data_temp,eb_size,w2v_win,mincount,epoch_size))\n",
    "                \n",
    "                temp = []\n",
    "                temp.append(data_title_sort[ind])\n",
    "            day_data_temp = day_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word2vec (only score larger than score threshold)\n",
    "# remove stop words\n",
    "\n",
    "import json\n",
    "import gensim\n",
    "import multiprocessing\n",
    "import bz2\n",
    "import math\n",
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "import time\n",
    "from backports import lzma\n",
    "import nltk\n",
    "#nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.corpora import Dictionary\n",
    "\n",
    "%cd Reddit\n",
    "\n",
    "# hyper parameters of word2vec\n",
    "eb_size = 50\n",
    "w2v_win = 5\n",
    "mincount = 100\n",
    "epoch_size = 10\n",
    "\n",
    "score_threshold = 10\n",
    "\n",
    "path = \"model_save_{0}_{1}_{2}_{3}_recommend\".format(eb_size,w2v_win,mincount,epoch_size)\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "# parameters to continue training\n",
    "ini = 1 # 0 if continue to train, 1 if initiate to train\n",
    "#year = 2017\n",
    "#month = 9\n",
    "#day_m = 30\n",
    "#model = gensim.models.Word2Vec.load(path + \"/w2v_trained_reddit_{0}_{1}_{2}_{3}_{4}_{5}_{6}_recommend\".format(year,int(month),day_m,eb_size,w2v_win,mincount,epoch_size))\n",
    "\n",
    "if os.path.isdir(path) == False:\n",
    "    os.mkdir(path)\n",
    "     \n",
    "sys.stdout = open(\"model_log_{0}_{1}_{2}_{3}_recommend.txt\".format(eb_size,w2v_win,mincount,epoch_size), \"a\")\n",
    "\n",
    "print(\"word2vec training\")\n",
    "print(datetime.datetime.now())\n",
    "print(\"embedding_size: {0}\".format(eb_size))\n",
    "print(\"w2v_window_size: {0}\".format(w2v_win))\n",
    "print(\"w2v_min_count: {0}\".format(mincount))\n",
    "print(\"w2v_epoch_size: {0}\".format(epoch_size))\n",
    "sys.stdout.flush()\n",
    "\n",
    "# there are few lines that are not in json format\n",
    "def is_json(line):\n",
    "    try:\n",
    "        json_object = json.loads(line)\n",
    "    except ValueError:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "for i in range(2011,2018):\n",
    "    for ii in range(1,13):\n",
    "        year = i\n",
    "        if ii<10:\n",
    "            month = \"0{0}\".format(ii)\n",
    "        else:\n",
    "            month = ii\n",
    "            \n",
    "        print(\"start: read file from bz2: {0}_{1}\".format(year,month))\n",
    "        print(datetime.datetime.now())\n",
    "        sys.stdout.flush()\n",
    "        \n",
    "        if os.path.isfile(\"RS_{0}-{1}.bz2\".format(year,month)):\n",
    "                data_file = bz2.BZ2File(\"RS_{0}-{1}.bz2\".format(year,month)).readlines()\n",
    "        elif os.path.isfile(\"RS_{0}-{1}.xz\".format(year,month)):\n",
    "                data_file = lzma.open(\"RS_{0}-{1}.xz\".format(year,month)).readlines()\n",
    "   \n",
    "        data_time = []\n",
    "        data_title = []\n",
    "        data_time_sort = []\n",
    "        data_title_sort = []\n",
    "        for line in data_file:\n",
    "            if is_json(line) is True:\n",
    "                line_load = json.loads(line)\n",
    "                if line_load[\"score\"] is not None:\n",
    "                    if int(line_load[\"score\"]) > score_threshold:\n",
    "                        data_time.append(int(line_load[\"created_utc\"]))\n",
    "                        temp_title = gensim.utils.simple_preprocess(line_load[\"title\"])\n",
    "                        data_title.append([temp_title for temp_title in temp_title if temp_title not in stop_words])\n",
    "                        #data_title.append(gensim.utils.simple_preprocess(line_load[\"title\"]))\n",
    "              \n",
    "        data_time_sort = sorted(data_time)\n",
    "        data_title_sort = [x for _,x in sorted(zip(data_time,data_title))]\n",
    "        \n",
    "        data_file.clear()\n",
    "        data_time.clear()\n",
    "        data_title.clear()\n",
    "        \n",
    "        print(\"end: read file from bz2: {0}_{1}\".format(year,month))\n",
    "        print(datetime.datetime.now())\n",
    "        sys.stdout.flush()\n",
    "        \n",
    "        for ind, ut in enumerate(data_time_sort):\n",
    "            ut_to_time = time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(ut))\n",
    "            day_data = int(ut_to_time[8:10])\n",
    "            if ind == 0:\n",
    "                day_data_temp = day_data\n",
    "                temp = []\n",
    "            \n",
    "            if day_data == day_data_temp: # cumulate data\n",
    "                temp.append(data_title_sort[ind])   \n",
    "            if day_data != day_data_temp or ind == len(data_time_sort) - 1: # update day & traning previous data(temp)\n",
    "                print([year,int(month), day_data_temp, datetime.datetime.now()])\n",
    "                sys.stdout.flush()\n",
    "                \n",
    "                '''\n",
    "                # gensim filter_extreme\n",
    "                temp_dic = Dictionary(temp)\n",
    "                #temp_dic.filter_extremes(no_below=1, no_above=0.2, keep_n=100000, keep_tokens=None)\n",
    "                temp_dic.filter_extremes(no_below=1, no_above=0.3)\n",
    "                \n",
    "                temp_list = []\n",
    "                for fi in range(len(temp_dic)):\n",
    "                    temp_list.append(temp_dic[fi])\n",
    "\n",
    "                temp_after_filter = []\n",
    "                for fi in temp:\n",
    "                    temp_after_filter.append([fi for fi in fi if fi in set(temp_list)])\n",
    "                ''' \n",
    "                \n",
    "                # training previous updated data\n",
    "                if ini == 1: # initial word2vec training\n",
    "                    model = gensim.models.Word2Vec(temp, size=eb_size, window=w2v_win, min_count=mincount,workers=2*multiprocessing.cpu_count())\n",
    "                    ini = 0\n",
    "                else: # online word2vec training\n",
    "                    model.build_vocab(temp, update=True)\n",
    "                model.train(temp,total_examples=len(temp),epochs=epoch_size)\n",
    "                model.save(path + \"/w2v_trained_reddit_{0}_{1}_{2}_{3}_{4}_{5}_{6}_recommend\".format(year,int(month),day_data_temp,eb_size,w2v_win,mincount,epoch_size))\n",
    "                # del temp_after_filter, temp_dic\n",
    "                \n",
    "                temp = []\n",
    "                temp.append(data_title_sort[ind])\n",
    "            day_data_temp = day_data\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
