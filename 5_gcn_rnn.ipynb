{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lapl_mat (982, 982)\n",
      "features (982, 7)\n",
      "lapl_mat (982, 982)\n",
      "features (982, 7)\n",
      "lapl_mat (982, 982)\n",
      "features (982, 7)\n",
      "lapl_mat (982, 982)\n",
      "features (982, 7)\n",
      "lapl_mat (982, 982)\n",
      "features (982, 7)\n",
      "WARNING:tensorflow:From /home/minyoung/data_minyoung/Research/GTAMON_data/share/GTAMON-Lablup/SeoHyeonDeok/gcn_prototype/gcn/model.py:175: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').\n",
      "WARNING:tensorflow:From <ipython-input-1-be43f01e565b>:91: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "(5, 7) [ 6.10799120e+07  2.21012980e+07 -4.72783000e+07 -1.06666216e+08\n",
      " -2.13608220e+07 -2.36767400e+07  1.11154910e+07] (1, 3)\n",
      "================================================================================\n",
      "Epoch - 9 label - 0 loss - 0.12635228\n",
      "================================================================================\n",
      "Epoch - 19 label - 0 loss - 0.08907665\n",
      "================================================================================\n",
      "Epoch - 29 label - 0 loss - 0.06508303\n",
      "================================================================================\n",
      "Epoch - 39 label - 0 loss - 0.049600072\n",
      "================================================================================\n",
      "Epoch - 49 label - 0 loss - 0.039314777\n",
      "================================================================================\n",
      "Epoch - 59 label - 0 loss - 0.032193992\n",
      "================================================================================\n",
      "Epoch - 69 label - 0 loss - 0.027047716\n",
      "================================================================================\n",
      "Epoch - 79 label - 0 loss - 0.02318127\n",
      "================================================================================\n",
      "Epoch - 89 label - 0 loss - 0.020180268\n",
      "================================================================================\n",
      "Epoch - 99 label - 0 loss - 0.017788751\n",
      "================================================================================\n",
      "Epoch - 109 label - 0 loss - 0.015841702\n",
      "================================================================================\n",
      "Epoch - 119 label - 0 loss - 0.014228678\n",
      "================================================================================\n",
      "Epoch - 129 label - 0 loss - 0.012873047\n",
      "================================================================================\n",
      "Epoch - 139 label - 0 loss - 0.01171978\n",
      "================================================================================\n",
      "Epoch - 149 label - 0 loss - 0.010728538\n",
      "================================================================================\n",
      "Epoch - 159 label - 0 loss - 0.009868878\n",
      "================================================================================\n",
      "Epoch - 169 label - 0 loss - 0.009117398\n",
      "================================================================================\n",
      "Epoch - 179 label - 0 loss - 0.008455784\n",
      "================================================================================\n",
      "Epoch - 189 label - 0 loss - 0.007869667\n",
      "================================================================================\n",
      "Epoch - 199 label - 0 loss - 0.0073474664\n",
      "================================================================================\n",
      "Epoch - 199 label - 0 loss - 0.0073474664\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import tensorflow as tf\n",
    "\n",
    "from model import build_model_reddit, build_rnn_reddit\n",
    "from config import reddit_num_input, reddit_learning_rate, reddit_num_classes\n",
    "\n",
    "with open(\"bitstamp_day.csv\",'r') as f:\n",
    "    bitcoin_daily = []\n",
    "    rdr = csv.reader(f)\n",
    "    for line in rdr:\n",
    "        bitcoin_daily.append(line)\n",
    "\n",
    "bitcoin_daily = np.array(bitcoin_daily)\n",
    "\n",
    "year = 2015\n",
    "month = 1\n",
    "lapl_mat_list = []\n",
    "features_list = []\n",
    "for i in range(reddit_num_input):\n",
    "    day = i + 1\n",
    "    with open(\"keyword/adj_{0}_{1}_{2}.csv\".format(year,month,day),'r') as f:\n",
    "        lapl_mat_temp = []\n",
    "        rdr = csv.reader(f)\n",
    "        for line in rdr:\n",
    "            lapl_mat_temp.append(line)\n",
    "\n",
    "    with open(\"keyword/features_{0}_{1}_{2}.csv\".format(year,month,day),'r') as f:\n",
    "        features_temp = []\n",
    "        rdr = csv.reader(f)\n",
    "        for line in rdr:\n",
    "            features_temp.append(line)\n",
    "\n",
    "    lapl_mat_temp = np.array(lapl_mat_temp) \n",
    "    features_temp = np.array(features_temp) \n",
    "\n",
    "    num_nodes = len(lapl_mat_temp)\n",
    "    if i == 0:\n",
    "        num_nodes_min = num_nodes\n",
    "    \n",
    "    # truncate adjacency_matrix & features\n",
    "    lapl_mat_temp = lapl_mat_temp[0:num_nodes_min,0:num_nodes_min]\n",
    "    features_temp = features_temp[0:num_nodes_min,:]\n",
    "    \n",
    "    lapl_mat = [None] * num_nodes_min\n",
    "    features = [None] * num_nodes_min\n",
    "\n",
    "    for ii in range(num_nodes_min):\n",
    "        lapl_mat[ii] = list(map(int, lapl_mat_temp[ii]))\n",
    "        features[ii] = list(map(float, features_temp[ii]))\n",
    "\n",
    "    lapl_mat = lapl_mat + np.eye(num_nodes_min)\n",
    "\n",
    "    features = np.array(features)\n",
    "\n",
    "    batch_size = 1\n",
    "\n",
    "    # bitcoin up/down\n",
    "    # one-hot vector\n",
    "    if i == reddit_num_input -1:\n",
    "        \n",
    "        ind_date = (bitcoin_daily[:,0]==str(year)) * (bitcoin_daily[:,1]==' '+str(month)) * (bitcoin_daily[:,2]==' '+str(day))\n",
    "        up_down = float(bitcoin_daily[ind_date,4])\n",
    "        label_for_rnn = np.zeros((batch_size, reddit_num_classes))\n",
    "        if up_down == 1:\n",
    "            label_for_rnn[:,0] = 1    \n",
    "        elif up_down == -1:\n",
    "            label_for_rnn[:,1] = 1    \n",
    "        else:\n",
    "            label_for_rnn[:,2] = 1\n",
    "\n",
    "    print(\"lapl_mat\", lapl_mat.shape)\n",
    "    print(\"features\", features.shape)\n",
    "    #print(\"labels\", labels.shape)\n",
    "    \n",
    "    lapl_mat_list.append(lapl_mat)\n",
    "    features_list.append(features)\n",
    "    \n",
    "\n",
    "tf_config = tf.ConfigProto()\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    \n",
    "    plhdr_label = tf.placeholder(tf.float32, \n",
    "                                 shape=(None, reddit_num_classes),\n",
    "                                 name='label')\n",
    "    \n",
    "    embedded_feature_list = build_model_reddit()\n",
    "    rnn_output = build_rnn_reddit(embedded_feature_list)\n",
    "    \n",
    "    cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=rnn_output, labels=plhdr_label))\n",
    "    train = tf.train.AdamOptimizer(reddit_learning_rate).minimize(cross_entropy)\n",
    "    \n",
    "    prediction = tf.argmax(rnn_output, 1)\n",
    "    correction = tf.argmax(label_for_rnn, 1)\n",
    "\n",
    "    correct_prediction = tf.cast(tf.equal(prediction, correction), tf.float32)\n",
    "    accuracy = tf.reduce_mean(correct_prediction)\n",
    "    \n",
    "    \n",
    "    \n",
    "with tf.Session(graph=graph, config=tf_config) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Generate fake feed_dict for list of input\n",
    "    feed_dict = dict()\n",
    "    feed_dict['label:0'] = label_for_rnn\n",
    "    for i in range(reddit_num_input):\n",
    "        feed_dict['input_{}:0'.format(i)] = features_list[i]\n",
    "        feed_dict['adj_{}:0'.format(i)] = lapl_mat_list[i]\n",
    "    \n",
    "    _embedded_feature_list = sess.run(embedded_feature_list, feed_dict=feed_dict)\n",
    "    _rnn_logits = sess.run(rnn_output, feed_dict=feed_dict)\n",
    "    \n",
    "    print(_embedded_feature_list.shape, _embedded_feature_list[0], _rnn_logits.shape)\n",
    "    \n",
    "    num_epoch = 200\n",
    "    for epoch in range(num_epoch):\n",
    "        sess.run(train, feed_dict=feed_dict)\n",
    "        if (1+epoch)%10 == 0:\n",
    "            _pred, _acc, _loss = sess.run([prediction, accuracy, cross_entropy], feed_dict=feed_dict)\n",
    "            print(\"=\"*80)\n",
    "            print(\"Epoch -\", epoch, \"label -\", _pred[0], \"loss -\", _loss)\n",
    "    _pred, _acc, _loss = sess.run([prediction, accuracy, cross_entropy], feed_dict=feed_dict)\n",
    "    print(\"=\"*80)\n",
    "    print(\"Epoch -\", 199, \"label -\", _pred[0], \"loss -\", _loss)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorf",
   "language": "python",
   "name": "tensorf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
